![image-20250221163131774](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250221163131774.png)

考虑e是如何被a影响的。如果我们以一倍的速度改变a，那么c也以一倍的速度改变，而c引起e以2倍速改变。 因此，e对a以1*2的速率改变。



## 因子路径（Factoring Path）

![img](https://pic2.zhimg.com/7135381d92d390586db9a95f333d9855_1440w.png)

![image-20250221171226417](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250221171226417.png)

![image-20250221171248982](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250221171248982.png)

前向微分跟踪输入是如何影响所有结点的，而逆向微分则跟踪每一个结点将如何影响到输出。也即，前向微分将操作符∂/∂X应用到每一个结点，而逆向微分则是将操作∂Z/∂应用到每一个结点。

## 计算向量

前向微分只给出了输出针对单个输入的导数，而逆向微分给出了输出针对每一个输入的导数。



在这个图中，这种方法只获得2倍的加速。如果想象一个有着上百万个输入、一个输入的场景，前向微分要求我们遍历图上百万次，而[逆向模式](https://zhida.zhihu.com/search?content_id=829257&content_type=Article&match_order=1&q=逆向模式&zhida_source=entity)则可以一次遍历就获得所有的导数。一个百万量级的加速是相当不错的！

当训练神经网络时，我们将代价（一个描述神经网络表现的数值）看作是参数（一组描述网络如何运作的数值）的函数。我们希望计算出代价对于每个参数的导数，以便运用[梯度下降法](https://zhida.zhihu.com/search?content_id=829257&content_type=Article&match_order=1&q=梯度下降法&zhida_source=entity)。百万个，或者上千万个参数现在在神经网络里已很常见了。因此，逆向微分，或者按神经网络场景下的叫法，后向传播，给了我们相当大的加速。a