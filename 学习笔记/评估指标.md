### **TOP_K 准确率**

TOP_K 准确率是分类和推荐系统中常用的评估指标，用于衡量正确类别或项目出现在模型预测的前K个结果中的频率。

Top-K准确率考虑的是预测结果中最有可能的K个结果是否包含有真实标签，如果包含则算预测正确，如果不包含则算预测错误。所以在这里我们能够知道，K值取得越大计算得到的Top-K准确率就会越高，极端情况下如果取K值为分类数，那么得到的准确率就肯定是1。但通常情况下我们只会看模型的Top-1、Top-3和Top-5准确率

假设有一个5分类问题，3个测试样本的真实标签和模型预测的类别概率如下：1

**样本1**:

- 真实标签: 3
- 预测概率: [0.1, 0.2, 0.4, 0.15, 0.15] (对应类别0-4)

**样本2**:

- 真实标签: 0
- 预测概率: [0.35, 0.25, 0.2, 0.1, 0.1]

**样本3**:

- 真实标签: 4
- 预测概率: [0.05, 0.15, 0.1, 0.2, 0.5]

**计算Top-2 Accuracy**:

1. 样本1: top2类别是[2,1] → 不包含3 → 错误
2. 样本2: top2类别是[0,1] → 包含0 → 正确
3. 样本3: top2类别是[4,3] → 包含4 → 正确

Top-2 Accuracy = 2/3 ≈ 66.67%



## map@k (Mean Average Precision at k)

- **Precision@k**: 在前k个推荐结果中相关项目的比例
- **Average Precision@k (AP@k)**: 对前k个结果中每个相关位置计算precision@k，然后取平均
- **Mean Average Precision@k (map@k)**: 对所有查询/用户的AP@k取平均

假设我们有3个用户，模型为每个用户推荐5个项目(k=5)，真实相关项目如下：

**用户1真实相关项目**: [A, C, D]
**用户2真实相关项目**: [B, E]
**用户3真实相关项目**: [A, D, F]

模型推荐结果：

| 用户 | 推荐排名 (1-5)  |
| :--- | :-------------- |
| 1    | [A, B, C, D, E] |
| 2    | [B, D, E, A, C] |
| 3    | [A, B, F, D, C] |

**计算AP@5**:

1. 用户1:
   - 相关位置: 1(A), 3(C), 4(D)
   - Precision@1: 1/1 = 1.0
   - Precision@3: 2/3 ≈ 0.666
   - Precision@4: 3/4 = 0.75
   - AP@5 = (1.0 + 0.666 + 0.75)/3 ≈ 0.805
2. 用户2:
   - 相关位置: 1(B), 3(E)
   - Precision@1: 1/1 = 1.0
   - Precision@3: 2/3 ≈ 0.666
   - AP@5 = (1.0 + 0.666)/2 ≈ 0.833
3. 用户3:
   - 相关位置: 1(A), 3(F), 4(D)
   - Precision@1: 1/1 = 1.0
   - Precision@3: 2/3 ≈ 0.666
   - Precision@4: 3/4 = 0.75
   - AP@5 = (1.0 + 0.666 + 0.75)/3 ≈ 0.805

**计算map@5**:
map@5 = (0.805 + 0.833 + 0.805)/3 ≈ 0.814

### **nn.CrossEntropyLoss**

  交叉熵损失函数（Cross-Entropy Loss）是机器学习中用于衡量两个概率分布之间差异的指标，特别适用于分类任务。它量化了模型预测的概率分布与真实分布之间的"距离"。

  多分类问题（3个类别）

**场景**：手写数字识别（0,1,2）

**输入数据**：
样本1：

- 真实标签：2 → one-hot编码：[0, 0, 1]
- 预测概率：[0.1, 0.2, 0.7]

样本2：

- 真实标签：0 → one-hot编码：[1, 0, 0]
- 预测概率：[0.8, 0.1, 0.1]

**计算损失**：

1. 样本1：- (0·log(0.1) + 0·log(0.2) + 1·log(0.7)) ≈ 0.357
2. 样本2：- (1·log(0.8) + 0·log(0.1) + 0·log(0.1)) ≈ 0.223

**平均损失**：(0.357 + 0.223)/2 ≈ 0.290

## 平均倒数排名 (Mean Reciprocal Rank, MRR)

平均倒数排名(MRR)是信息检索和推荐系统中常用的评估指标，用于衡量系统返回的相关结果在排名列表中的位置质量。它特别关注第一个相关结果的排名位置。

RR(q) = 1 / rank_i

  rank_i：第一个相关结果在返回列表中的位置(排名)   如果没有相关结果，RR(q) = 0

评估推荐列表前5项的相关性：

**用户1**：
推荐排名：[I3, I1√, I5, I2, I4]
第一个相关项I1在位置2 → RR = 1/2 = 0.5

**用户2**：
推荐排名：[I7√, I8, I9, I2, I1]
第一个相关项I7在位置1 → RR = 1/1 = 1.0

**用户3**：
推荐排名：[I4, I5, I6, I2, I1]
无相关项 → RR = 0

**MRR计算**：
MRR = (0.5 + 1.0 + 0) / 3 ≈ 0.5
