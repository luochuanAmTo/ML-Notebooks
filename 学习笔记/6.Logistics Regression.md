```python
### Import the usual libraries
import torch #提供张量（tensor）操作、自动求导和深度学习模型的构建与训练等功能。
import torchvision #一个专门为计算机视觉任务提供的库，包含常用的图像处理功能和预训练模型。它可以帮助用户下载和加载数据集，进行数据增强等操作
import torch.nn as nn #PyTorch 的神经网络模块，提供多种神经网络构建块（如层、损失函数等）
from torchvision import datasets, models, transforms #datasets包含多种标准数据集
 #models 提供一些预训练的图像分类模型，例如 ResNet、VGG 等  transforms：torchvision 中的子模块，提供数据增强和图像转换的工具，可以对图像进行各种预处理操作，比如调整大小、裁剪、归一化等 a
import os
import numpy as np
import matplotlib.pyplot as plt

%matplotlib inline
```

```python
## configuration to detect cuda or cpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print (device) #选择设备
```

```python
# download the data
!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip #下载数据
!unzip hymenoptera_data.zip  #解压缩
```



```python
# configure root folder on your gdrive
data_dir = 'hymenoptera_data'

# custom transformer to flatten the image tensors
class ReshapeTransform: # 是一个自定义的变换类，用于将图像张量重塑为指定的形状
    def __init__(self, new_size): #初始化方法，接受一个 new_size 参数，表示重塑后的目标形状。
        self.new_size = new_size 

    def __call__(self, img):  #调用方法，接受一个图像张量 img，并使用 torch.reshape 将其重塑为 new_size 指定的形状。
        result = torch.reshape(img, self.new_size)
        return result

# transformations used to standardize and normalize the datasets定义数据预处理变换
data_transforms = {  #是一个字典，包含训练集和验证集的预处理流程。
    'train': transforms.Compose([  #用于将多个变换组合在一起
        transforms.Resize(224), #将图像调整为 224x224 像素
        transforms.CenterCrop(224),  #从图像中心裁剪出 224x224 像素的区域
        transforms.ToTensor(),  #将图像转换为 PyTorch 张量，并将像素值归一化到 [0, 1] 范围。
        ReshapeTransform((-1,)) # flattens the data  将图像张量展平为一维向量
    ]),
    'val': transforms.Compose([
        transforms.Resize(224),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        ReshapeTransform((-1,)) # flattens the data
    ]),
}

# load the correspoding folders
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}
#是一个字典，包含训练集和验证集的 ImageFolder 对象
#datasets.ImageFolder 是 PyTorch 提供的一个类，用于从文件夹加载图像数据集。它会自动根据子文件夹名称分配标签。
#os.path.join(data_dir, x)：构建训练集和验证集的路径。
 #data_transforms[x]：应用相应的预处理变换。
    
    #创建训练集的 DataLoader
# load the entire dataset; we are not using minibatches here
train_dataset = torch.utils.data.DataLoader(image_datasets['train'],
                                            batch_size=len(image_datasets['train']),
                                            shuffle=True)
#创建验证集的 DataLoader
test_dataset = torch.utils.data.DataLoader(image_datasets['val'],
                                           batch_size=len(image_datasets['val']),
                                           shuffle=True)
```



```python
# load the entire dataset
x, y = next(iter(train_dataset)) #train_dataset 是一个 DataLoader 对象，包含了训练集的数据。   iter(train_dataset)：将 DataLoader 转换为一个迭代器。  next(...)：从迭代器中获取下一个批次的数据。x 是图像数据，y 是对应的标签

# print one example  #x.shape：获取图像数据的形状。假设 x 的形状是 (N, C, H, W)，
#N 是样本数量。 C 是通道数（例如 3，表示 RGB 图像）。 H 是图像高度。 W 是图像宽度。
 #获取标签数据的形状。假设 y 的形状是 (N,)，其中 N 是样本数量
dim = x.shape[1]  #获取图像的通道数（C）。
print("Dimension of image:", x.shape, "\n", 
      "Dimension of labels", y.shape)

plt.imshow(x[160].reshape(1, 3, 224, 224).squeeze().T.numpy())

reshape(1, 3, 224, 224)：将图像数据重塑为形状 (1, 3, 224, 224)，即：
1：批次大小为 1。
3：通道数为 3（RGB）。
224：图像高度为 224。
224：图像宽度为 224
squeeze()：去除维度为 1 的轴，将形状从 (1, 3, 224, 224) 变为 (3, 224, 224)。
转置操作，将形状从 (3, 224, 224) 变为 (224, 224, 3)，以便符合 matplotlib 的图像显示格式（高度、宽度、通道）
```



```python
class LR(nn.Module): #定义一个逻辑回归模型类 LR，继承自 nn.Module（
    def __init__(self, dim, lr=torch.scalar_tensor(0.01)):
        super(LR, self).__init__() #super(LR, self).__init__()：调用父类 nn.Module 的初始化方法 
        # intialize parameters 
        self.w = torch.zeros(dim, 1, dtype=torch.float).to(device)# 初始化权重参数 w，形状为 (dim, 1)，并将其设置为全零张量
        self.b = torch.scalar_tensor(0).to(device) #初始化偏置参数 b，并将其设置为标量 0。 to(device)：将张量移动到指定的设备
        self.grads = {"dw": torch.zeros(dim, 1, dtype=torch.float).to(device), 
                      "db": torch.scalar_tensor(0).to(device)}
         #初始化梯度字典 grads，包含权重梯度 dw 和偏置梯度 db，并将其设置为全零张量。to(device)：将张量移动到指定的设备。
        self.lr = lr.to(device)  #初始化学习率 lr，

    def forward(self, x): #模型的前向传播过程。
        # compute forward
        z = torch.mm(self.w.T, x) + self.b  #计算权重 w 和输入 x 的矩阵乘法。
        a = self.sigmoid(z)#结果 z 应用 sigmoid 激活函数。
        return a  #返回激活值 a（即预测值）

    def sigmoid(self, z):
        # compute sigmoid
        return 1/(1 + torch.exp(-z)) #定义 sigmoid 激活函数，将输入 z 映射到 [0, 1] 范围内。

    def backward(self, x, yhat, y):
        # compute backward
        self.grads["dw"] = (1/x.shape[1]) * torch.mm(x, (yhat - y).T)#计算权重梯度 dw。
        self.grads["db"] = (1/x.shape[1]) * torch.sum(yhat - y) #计算偏置梯度 db
    
    def optimize(self):
        # optimization step #optimize 方法根据梯度更新模型的参数。
        self.w = self.w - self.lr * self.grads["dw"]
        self.b = self.b - self.lr * self.grads["db"]

## utility functions
def loss(yhat, y):
    m = y.size()[1]
    return -(1/m)* torch.sum(y*torch.log(yhat) + (1 - y)* torch.log(1-yhat))  #返回平均损失。

def predict(yhat, y):
    y_prediction = torch.zeros(1, y.size()[1])  #初始化预测结果张量，形状为 (1, 样本数量)。
    for i in range(yhat.size()[1]):
        if yhat[0, i] <= 0.5:
            y_prediction[0, i] = 0  #如果 yhat[0, i] <= 0.5，预测为 0。
        else:
            y_prediction[0, i] = 1
    return 100 - torch.mean(torch.abs(y_prediction - y)) * 100 #计算预测值与真实值的绝对误差。  torch.mean(...)：计算平均误差

```



```python
# model pretesting
x, y = next(iter(train_dataset))#x：训练数据的特征（图像数据）。y：训练数据的标签。
# flatten/transform the data
x_flatten = x.T
y = y.unsqueeze(0) 

# num_px is the dimension of the images
dim = x_flatten.shape[0]  #x_flatten.shape[0]：获取输入数据的特征维度（即图像的展平后的像素数量）

# model instance
model = LR(dim)
model.to(device)
yhat = model.forward(x_flatten.to(device)) #通过模型进行前向传播，得到预测值 yhat。
yhat = yhat.data.cpu() #yhat.data.cpu()：将预测值 yhat 从 GPU 移动到 CPU，并提取其数据部分。



# calculate loss
cost = loss(yhat, y) #用损失函数，计算预测值 yhat 和真实标签 y 之间的损失（二元交叉熵损
prediction = predict(yhat, y)#predict(yhat, y)：调用预测函数，计算当前批次的准确率。
print("Cost: ", cost)
print("Accuracy: ", prediction)

# backpropagate
model.backward(x_flatten.to(device), yhat.to(device), y.to(device))
model.optimize()
```

train THE model

```python
# hyperparams
costs = [] #存储每次迭代的训练损失。
dim = x_flatten.shape[0] #获取输入数据的特征维度（即图像的展平后的像素数量）
learning_rate = torch.scalar_tensor(0.0001).to(device) #定义学习率 learning_rate，并将其设置为标量张量 0.0001。
num_iterations = 500 #定义训练的总迭代次数为 500。
lrmodel = LR(dim, learning_rate)  #创建一个逻辑回归模型实例 lrmodel，传入输入数据的维度 dim 和学习率 learning_rate。
lrmodel.to(device)

# transform the data
def transform_data(x, y):
    x_flatten = x.T
    y = y.unsqueeze(0)  #在标签 y 的第 0 维增加一个维度，使其形状从 (样本数量,) 变为 (1, 样本数量)。
    return x_flatten, y 

# train the model
for i in range(num_iterations):  #迭代 num_iterations 次（500 次）。
    x, y = next(iter(train_dataset))  #将训练和测试数据 DataLoader 转换为迭代器。
     #分别获取训练数据的特征和标签
    test_x, test_y = next(iter(test_dataset))
    x, y = transform_data(x, y)
    test_x, test_y = transform_data(test_x, test_y)

    # forward
    yhat = lrmodel.forward(x.to(device))
    #将训练数据 x 移动到指定设备，并通过模型进行前向传播，得到预测值 yhat
    cost = loss(yhat.data.cpu(), y) #调用损失函数，计算预测值 yhat 和真实标签 y 之间的损失（二元交叉熵损失）
    train_pred = predict(yhat, y)  #调用 predict 函数，计算当前批次的训练准确率。
        
    # backward
    lrmodel.backward(x.to(device),  #用反向传播方法，计算损失函数对模型参数的梯度。
                    yhat.to(device), 
                    y.to(device))
    lrmodel.optimize() #调用优化方法，根据梯度更新模型的参数。



    # test
    yhat_test = lrmodel.forward(test_x.to(device)) #将测试数据 test_x 移动到指定设备，并通过模型进行前向传播，得到测试预测值 yhat_test。


    test_pred = predict(yhat_test, test_y)  ￥调用 predict 函数，计算测试准确率

    if i % 10 == 0:
        costs.append(cost)

    if i % 10 == 0:
        print("Cost after iteration {}: {} | Train Acc: {} | Test Acc: {}".format(i, 
                                                                                    cost, 
                                                                                    train_pred,
                                                                                    test_pred))
```

