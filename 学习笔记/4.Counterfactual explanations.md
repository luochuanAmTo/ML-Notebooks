反事实解释（CEs）属于前面提到的第一类方法，即用于解释**黑箱模型**的方法。我们考虑一个分类器模型的情况，即模型是一个函数：
$$
f: \Omega \to \mathbb{C}
$$
  Ωd是特征空间，包含 d个特征（有些是数值型的，例如在 R中，有些是类别型的）。

  C是类别空间。例如，在信用风险分类器中，C={高风险,低风险}。

假设 x∈Ωd是分类器 *f* 的一个输入，代表一个用户。

*x*=(年龄:22,性别:女性,储蓄:5.000,   对于给定的 x，模型*f* 会预测一个类别 c（例如“高风险”）。反事实解释的目标是回答以下问题

需要对 x 进行哪些小的修改，才能使新的输入 x′导致模型 f* 输出期望的类别 c*

*f*(*x*′)=低风险）  一个反事实解释可能是：用户需要增加储蓄（从 5.000增加到8.000增加到8.000）

 用户需要改变职业（从“学生”变为“兼职工作”）

  如果模型仅基于种族或性别的变化（其他特征保持不变）就改变了预测结果，这表明模型可能从历史数据中学到了有害的偏见，导致对少数群体的不公平歧视

在反事实解释（Counterfactual Explanations, CEs）中，我们试图对输入 *x* 进行**小的修改**，以观察模型 *f* 在输入附近的行为，从而了解该区域的决策边界是什么样的。这种方法的核心思想是通过微调输入特征，探索模型决策的敏感性和逻辑。距离函数 *δ* 用于衡量 *x* 和 ′*x*′ 之间的差异。这个函数需要能够捕捉干预的成本，因此它应该根据具体应用场景进行定义。

##### 开始实验：模拟金融信用风险场景

我们使用一个模拟的信用风险数据集，其中包含用户的特征（如年龄、收入、储蓄、职业、信用评分等）以及标签（高风险或低风险）,使用随机森林（Random Forest）作为黑箱模型，因为它是一个强大的分类器，但内部机制复杂，难以直接解释，从测试集中选择一个被模型预测为“高风险”的用户样本 *x*，使用反事实解释算法（如DiCE、Wachter等）来生成反事实样本 ′*x*′，算法的目标是找到一个与 *x* 相似但被模型预测为“低风险”的 ′*x*′，如果反事实解释不合理，可能需要调整算法参数或重新定义距离函数 *δ*

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier #随机森林分类器
from sklearn.model_selection import train_test_split  #数据计划分
from sklearn.metrics import accuracy_score, balanced_accuracy_score  #评估模型分类性能

SEED = 42
np.random.seed(SEED) # for reproducibility
# clone repo, access, and install repo
%cd content
%cd ..
! pwd

# Load data set & do some pre-processing
df = pd.read_csv("south_german_credit.csv")  
df.drop("account_check_status",axis=1,inplace=True) #删除名为account_check_status的列
categorical_feature_names = ['purpose', 'personal_status_sex',  #定义类别型特征的列名列表
    'other_debtors', 'other_installment_plans', 'telephone', 'foreign_worker']
            #这些特征是离散的，通常需要转换为数值形式以便模型处理
label_name = 'credit_risk'  #定义目标变量（标签）的列名为credit_risk
desired_class = 1 # this means "low risk"

for feat in categorical_feature_names: # convert categorical features into integer codes
    df[feat] = pd.Categorical(df[feat])  #将特征转换为Pandas的类别类型
    df[feat] = df[feat].cat.codes   #将类别型特征转换为整数编码（例如，purpose中的类别car可能被编码为0，education为1，等等
feature_names = list(df.columns)   #获取DataFrame的所有列名，并将其转换为列表
feature_names.remove(label_name) #从特征列表中移除目标变量（标签）列名。

print("Num. features: {}, feature names: {}".format(len(feature_names), feature_names))

# Prepare data to be in numpy format, as typically used to train a scikit-learn model
X = df[feature_names].to_numpy() #将特征数据转换为NumPy数组，用于模型训练
y = df[label_name].to_numpy().astype(int)
# Assume we have a specific train & test split  将数据集划分为训练集和测试集：
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)
```

![image-20250223201117593](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250223201117593.png)

```python
# Train black-box model (bbm)
bbm = RandomForestClassifier(random_state=SEED, class_weight="balanced", min_samples_leaf=25)  #定义并训练黑箱模型（随机森林分类器）
bbm.fit(X_train, y_train)     #训练模型         
# note: we do not one-hot encode multi-category features here for simplicity  评估模型
print("acc:{:.3f}, bal.-acc:{:.3f}".format(accuracy_score(y_test, bbm.predict(X_test)), balanced_accuracy_score(y_test, bbm.predict(X_test)))) #模型在测试机集上的准确率，和平衡准确率
```

![image-20250223204545560](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250223204545560.png)

```python
# Let's consider, e.g., the last test sample for which an undesired decision is given
p = bbm.predict(X_test)  #使用训练好的随机森林模型（bbm）对测试集（X_test）进行预测， 
     #p：是一个数组，包含测试集中每个样本的预测类别（例如，0表示高风险，1表示低风险）
idx = np.argwhere(p != desired_class).squeeze()[-1]  #选择最后一个被预测为不符合期望类别的样本
x = X_test[idx] # this is our unhappy user!  #表示这个样本的特征值，即一个被模型预测为不符合期望类别（高风险）的用户

# show features of this user
print("Description of x:")
for i, feat_name in enumerate(feature_names):
  print(" ", feat_name+" "*(30-len(feat_name)), x[i])
```

![image-20250228093157418](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250228093157418.png)

```python
#定义每个特征的搜索范围，确保反事实样本的合理性，设置特征的合理性约束，限制某些特征的修改方式
# Set up search bounds
feature_intervals = list()  #初始化一个空列表，用于存储每个特征的搜索范围
for i, feat in enumerate(feature_names):  
  if feat in categorical_feature_names:  #判断当前特征是否为类别型特征。
    interval_i = np.unique(X_train[:,i]) #获取训练集中该特征的所有唯一值，作为搜索范围。
  else:
    interval_i = (np.min(X_train[:,i]), np.max(X_train[:,i]))
  feature_intervals.append(interval_i)  #如果是数值型特征，获取训练集中股特征的最大值和最小值，作为搜索范围。

# Set up which feature indices are categorical
indices_categorical_features = [i for i, feat in enumerate(feature_names) if feat in categorical_feature_names]  #ndices_categorical_features：存储所有类别型特征在 feature_names 中的索引

# Let's also set up a plausibility constraint for the feature "age" (can only increase)
# and one for foreign worker (cannot change, must stay equal to what it is)
pcs = ['>=' if feat=='age' else ('=' if feat=='foreign_worker' else None) for feat in feature_names]
对于特征 age，设置约束为 >=，表示反事实样本中的年龄只能增加（不能减少）。
对于特征 foreign_worker，设置约束为 =，表示反事实样本中的该特征值必须保持不变。
对于其他特征，不设置约束（None）。
```



```python
from cogs.evolution import Evolution  #进化算法的核心类，用于生成反事实样本。
from cogs.fitness import gower_fitness_function  #适应度函数，用于评估生成的反事实样本的质量。

cogs = Evolution(
        ### hyper-parameters of the problem (required!) ###
        x=x,  #起点，即当前不满意的用户样本（x 是从测试集中选择的样本
        fitness_function=gower_fitness_function,  #一个经典的适应度函数，适用于反事实解释。
        fitness_function_kwargs={'blackbox':bbm,'desired_class': desired_class},  黑箱模型（这里是随机森林分类器）
        feature_intervals=feature_intervals,  # 每个特征的搜索范围，确保生成的反事实样本在合理范围内。
        indices_categorical_features=indices_categorical_features,  # the indices of the features that are categorical   类别特征的索引
        plausibility_constraints=pcs, # can be "None" if no constraints need to be set
        ### hyper-parameters of the evolution (all optional) ###特征的约束
        evolution_type='classic',       # the type of evolution, classic works quite  well  进化算法类型
        population_size=1000,           # how many candidate counterfactual examples to evolve simultaneously  每代候选反事实样本的数量
        n_generations=25,               # number of iterations for the evolution进化的迭代次数
        selection_name='tournament_4',  # selection pressure 选择策略，每次从4个候选样本中选择最优的
        init_temperature=0.8, # how "far" from x we initialize  ，控制初始种群与输入样本的差异
        num_features_mutation_strength=0.25, # strength of random mutations for numerical features  数值型特征的突变强度，控制每次突变时数值型特征的变化幅度。
        num_features_mutation_strength_decay=0.5, #突变强度的衰减率，用于在进化过程中逐步减小突变强 decay for the hyper-param. above
        num_features_mutation_strength_decay_generations=[10,15,20], # when to apply the decay  突变强度衰减的迭代次数（在第 10、15、20 代时衰减）。
        ### other settings ###
        verbose=True  # logs progress at every generation 
)
```



```python
from pandas.core.arrays import categorical
# Get the best-found counterfactual example (called elite)
cf_example = cogs.elite  #进化算法（cogs）找到的最优反事实样本
cf_explanation = cogs.elite - x   #计算最优反事实样本与原始样本 x 的差异。

# Show counterfactual explanation
if bbm.predict([cf_example])[0] == desired_class: 使用黑箱模型（bbm）对最优反事实样本进行预测
  print("Success! Here's the explanation:") 
  for i, feat in enumerate(feature_names):  #遍历所有特征。
    if cf_explanation[i] != 0:    #检查当前特征是否需要修改（差异不为 0）
      print(" Feature '{}' should change from '{}' to '{}'".format(feat, np.round(x[i],3), np.round(cf_example[i],3)))   #输出需要修改的特征及其变化值。feat：特征名称
   # x[i]：原始样本中该特征的值。 cf_example[i]：最优反事实样本中该特征的值。
else: #未找到
  print("Failed to find a counterfactual explanation for the desired class :(")
```

![image-20250228105039718](C:\Users\AmTo2\AppData\Roaming\Typora\typora-user-images\image-20250228105039718.png)

a
